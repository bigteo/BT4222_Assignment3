{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A3_A0203989N.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "sEknxYKtjfzK",
        "F7-7B5iwrNYB",
        "2Uf123B7jiCD"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QelXyP-0hiT5"
      },
      "source": [
        "# BT4222 Assignment 3\n",
        "By Teo Zhi Feng (A0203989N)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMzTMwKfhvdl"
      },
      "source": [
        "# 1 Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-UQHsr9hhtH"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "from tensorflow.keras.datasets import imdb"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqMcUIrQjAdQ"
      },
      "source": [
        "# fix random seed for reproducibility\n",
        "np.random.seed(123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ByVIc8d0aC0"
      },
      "source": [
        "#### Import IMDB Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKH4gT460Pv9"
      },
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4g2gHFSvmWPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23066974-ca1b-44ae-b277-a628fd2631d1"
      },
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  19.5M      0  0:00:04  0:00:04 --:--:-- 19.5M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmRrVV4osYQi"
      },
      "source": [
        "#### Inspect folder directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGUHXRDqmWHC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9137f73c-db22-4c6a-a0d0-8dc21983afa0"
      },
      "source": [
        "!ls aclImdb\n",
        "!ls aclImdb/test\n",
        "!ls aclImdb/train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imdbEr.txt  imdb.vocab\tREADME\ttest  train\n",
            "labeledBow.feat  neg  pos  urls_neg.txt  urls_pos.txt\n",
            "labeledBow.feat  pos\tunsupBow.feat  urls_pos.txt\n",
            "neg\t\t unsup\turls_neg.txt   urls_unsup.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMHf2EeonDTg"
      },
      "source": [
        "!rm -r aclImdb/train/unsup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te5c4IfYsj1N"
      },
      "source": [
        "#### Import dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqnfXcXJnDPo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8fe9f40-61fd-459a-9b2a-8834f19ef8b7"
      },
      "source": [
        "batch_size = 32\n",
        "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=1337,\n",
        ")\n",
        "raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=1337,\n",
        ")\n",
        "raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    \"aclImdb/test\",\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "print(f\"Number of batches in raw_train_ds: {raw_train_ds.cardinality()}\")\n",
        "print(f\"Number of batches in raw_val_ds: {raw_val_ds.cardinality()}\")\n",
        "print(f\"Number of batches in raw_test_ds: {raw_test_ds.cardinality()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Number of batches in raw_train_ds: 625\n",
            "Number of batches in raw_val_ds: 157\n",
            "Number of batches in raw_test_ds: 782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8RbfM0ysoGD"
      },
      "source": [
        "#### Inspect dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTE61hxtsCg-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eae7ed1-4bed-4de3-fa0c-522b3ca741a1"
      },
      "source": [
        "for text_batch, label_batch in raw_train_ds.take(1):\n",
        "    for i in range(5):\n",
        "        print(text_batch.numpy()[i])\n",
        "        print(label_batch.numpy()[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'This is one of the worst movies i have seen to date, the best part was Christian J. Meoli \"Leonard\" attempting to act jumping up and down outside the bar, kind-of like i wanted to do on the DVD, to spare the rest of humanity the agony of watching this shitty film. It has a great cast so you keep watching waiting for it to get good, i mean with Sean Astin \"Andrew\" (played his part perfectly, did a great job, too bad it was in this film), Kyra Sedgwick \"Bevan\", Ron Livingston \"Chad\", Ren\\xc3\\xa9e Zellweger \"Poet\" (they put her name on the cover she has a total of 1 line and less then 4 seconds in the whole movie...<br /><br />If the cast had any dignity, they would go out and buy all the copies of this film and burn them along with Writer / Director George Hickenlooper and Writer John Enbom'\n",
            "0\n",
            "b\"I agree that Capital City should be on DVD. I watched this show only by accident in 1994 and fell in love with Rolf Saxon as Hudson Talbot. It was nice to see Americans who work abroad in London in the financial industry for a change. I loved Rolf in this role and loved every other role that he has been in. I can't believe the show only lasted 13 episodes. I liked William Armstrong as Hudson's flamboyant charming friend in the series. When they aired this show in the New York City area, it was always late at night or at off times. The show is less than an hour long. I felt this show should have gone on longer but the casting changes in the second season really made the show a little less interesting. I didn't care for Sylvia but missed the actress, Julia Phillips-Lane in the previous season. I felt this show took chances and often it worked. It showed Americans who loved and chose to live in London. The American characters were not arrogant or tried to outdo their British counterparts. I also liked the fact that they had tried to internationalize the cast rather than make them all British. I liked watching Julia Ormond in an early role. I felt this show should have lasted longer. I felt at times that the previews lasted as long as the show in less than an hour. They could have transferred the cast to New York City and it would have been a hit in America.\"\n",
            "1\n",
            "b\"It was nice to see all the familiar characters again, but the story bothered me. We loved Ariel in the first movie- so why is the second one centered around her daughter? The new characters were annoying and I didn't like the plot of this. Worst of all, Christopher Daniel Barnes didn't come back as the voice of Eric! Disney, please stop remaking classic movies with these shoddy imitations.\"\n",
            "0\n",
            "b'I haven\\'t actually finished the film. You may say that in this case I have no right to review it, especially so negatively. But I do, only because I stopped it on account of I couldn\\'t watch anymore...I got over halfway, and I only got there by promising myself something good was just around the corner. This film is so tiresome, so lackluster that I was actually insulted. I haven\\'t read many of the other reviews, so I\\'m not sure if there are other homosexual teens who have suffered through it, but I am homosexual, and I did go through \"similar\" revelations, day dreams, issues etc etc. There were maybe two moments where I actually felt this film could go somewhere, where I felt it may have some inkling of meaning, or relativity, but these hopes were dashed the moment the next set of clich\\xc3\\xa9-ridden narration came on. I mean, just look at the quotes on the IMDb page. Unfortunately you\\'re not able to hear the scratchy play back, nor the echo-ey fades if you\\'re just read the quotes, because they are just too painful/ridiculous/stupid to miss. I did give the film three stars, and all three of those stars go to the films cinematographer who did a fantastic job attempting to transform Archer\\'s tired \"concepts\" into something watchable. Mind you, I pray he wasn\\'t the one who decided to include all the long shots of TV closeups...another unnecessary clich\\xc3\\xa9 already over done in films such as Korine\\'s Gummo... I think it is extremely fitting that this film premiered at Sundance (only because Archer had connections in the festival via volunteer work he did, by the way...) because Sundance seems to be the one festival where clich\\xc3\\xa9 heavy drivel like this is still accepted as \"arthouse\". No, it\\'s not art house, I\\'m afraid it\\'s just plain s**t-house. Do not watch.'\n",
            "0\n",
            "b'An excellent movie. Superb acting by Mary Alice, Phillip M. Thomas, and a young Irene Cara. Tony King was very realistic in his role of Satin. This movie was one of the last predominately \"all black\" movies of the 70\\'s and unlike the \"blaxploitation\" movies of that era, this movie actually had a plot, and was very well done. The movie soundtrack, sung by Aretha Franklin, was popular on the R&B charts at the time.'\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9u1MUVaKoMq9"
      },
      "source": [
        "# 2 Data Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq3d8Lm-oQ5w"
      },
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "import string\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsA9pKy4tLy-"
      },
      "source": [
        "#### Standardise text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPim7cIQnDGI"
      },
      "source": [
        "# Having looked at our data above, we see that the raw text contains HTML break\n",
        "# tags of the form '<br />'. These tags will not be removed by the default\n",
        "# standardizer (which doesn't strip HTML). Because of this, we will need to\n",
        "# create a custom standardization function.\n",
        "def custom_standardization(input_data):\n",
        "    lowercase = tf.strings.lower(input_data)\n",
        "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
        "    return tf.strings.regex_replace(\n",
        "        stripped_html, f\"[{re.escape(string.punctuation)}]\", \"\"\n",
        "    )\n",
        "\n",
        "\n",
        "# Model constants.\n",
        "max_features = 20000\n",
        "embedding_dim = 128\n",
        "sequence_length = 500\n",
        "\n",
        "# Now that we have our custom standardization, we can instantiate our text\n",
        "# vectorization layer. We are using this layer to normalize, split, and map\n",
        "# strings to integers, so we set our 'output_mode' to 'int'.\n",
        "# Note that we're using the default split function,\n",
        "# and the custom standardization defined above.\n",
        "# We also set an explicit maximum sequence length, since the CNNs later in our\n",
        "# model won't support ragged sequences.\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=max_features,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "\n",
        "# Now that the vocab layer has been created, call `adapt` on a text-only\n",
        "# dataset to create the vocabulary. You don't have to batch, but for very large\n",
        "# datasets this means you're not keeping spare copies of the dataset in memory.\n",
        "\n",
        "# Let's make a text-only dataset (no labels):\n",
        "text_ds = raw_train_ds.map(lambda x, y: x)\n",
        "\n",
        "# Let's call `adapt`:\n",
        "vectorize_layer.adapt(text_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsjBQhU3tQHo"
      },
      "source": [
        "#### Vectorise text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB1DJBInpWnO"
      },
      "source": [
        "def vectorize_text(text, label):\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    return vectorize_layer(text), label\n",
        "\n",
        "\n",
        "# Vectorize the data.\n",
        "train_ds = raw_train_ds.map(vectorize_text)\n",
        "val_ds = raw_val_ds.map(vectorize_text)\n",
        "test_ds = raw_test_ds.map(vectorize_text)\n",
        "\n",
        "# Do async prefetching / buffering of the data for best performance on GPU.\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=10)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=10)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjAScOtRyT_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b6e05f1-3b82-4363-bd6e-63ca6180ac97"
      },
      "source": [
        "train_ds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None, 500), (None,)), types: (tf.int64, tf.int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P57Qdd-QtUQD"
      },
      "source": [
        "#### Inspect pre-processed dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3CnRHv3pj_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b9ca635-ad47-4c45-85f1-ba6875f7d3ff"
      },
      "source": [
        "text_batch, label_batch = next(iter(raw_train_ds))\n",
        "first_review, first_label = text_batch[0], label_batch[0]\n",
        "print(\"Review\", first_review)\n",
        "print(\"Label\", raw_train_ds.class_names[first_label])\n",
        "print(\"Vectorized review\", vectorize_text(first_review, first_label))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review tf.Tensor(b\"As if there weren't enough of those floating around at the time already, we have here another lame GODFATHER clone from the director of IL CONSIGLIORI (1973) which I had watched earlier this year. The marquee-value name roped in this time is Telly Savalas who belatedly enters the proceedings and is first seen from behind, rather campily tending to his flowers and wearing a beret in the style of French painters! Apart from not looking minimally Sicilian, he sports no accent of any kind other than his familiar drawl. Antonio Sabato, then, makes for an unlikely gangster - apart from being a resistible leading man; his relationship with Savalas, which becomes paternal at the flick of an eye, is also unconvincing (especially since he subsequently becomes romantically involved with the latter's spirited teenage niece)! Besides, for a gangster flick, there's precious little action to speak of and none of it is in any way memorable (though the finale set in a clinic is well enough handled); furthermore, the score by Francesco De Masi is serviceable but nothing else. Incidentally, the bargain-basement DVD I rented starts off midway through the credits so that none of the cast members - or even the film's title - is ever listed!\", shape=(), dtype=string)\n",
            "Label neg\n",
            "Vectorized review (<tf.Tensor: shape=(1, 500), dtype=int64, numpy=\n",
            "array([[   14,    44,    47,  1142,   189,     5,   143,  5219,   182,\n",
            "           30,     2,    58,   439,    71,    25,   128,   157,   828,\n",
            "         3333,  6877,    36,     2,   172,     5,  8286,     1,  4593,\n",
            "           61,    11,    65,   282,   876,    10,   339,     2,     1,\n",
            "          401,     1,     8,    10,    58,     7,  9978, 11300,    35,\n",
            "            1,  3472,     2,  3879,     3,     7,    85,   107,    36,\n",
            "          491,   237,     1, 17268,     6,    23,  5678,     3,  1737,\n",
            "            4,     1,     8,     2,   427,     5,   809, 12107,   930,\n",
            "           36,    21,   287,     1, 19740,    26,  2355,    57,  1173,\n",
            "            5,    98,   238,    81,    70,    23,  1063, 19138,  6446,\n",
            "            1,    91,   155,    15,    33,  2353,  2314,   930,    36,\n",
            "          104,     4,     1,   975,   131,    23,   609,    16, 11300,\n",
            "           61,   442,     1,    30,     2,   503,     5,    33,   799,\n",
            "            7,    80,  2585,   257,   234,    26,  7716,   442, 13535,\n",
            "          560,    16,     2,     1,  5037,  1690,  6074,  1368,    15,\n",
            "            4,  2314,   503,   213,  3431,   111,   216,     6,  1107,\n",
            "            5,     3,   597,     5,     9,     7,     8,    98,    92,\n",
            "          853,   148,     2,  1963,   274,     8,     4,  7989,     7,\n",
            "           73,   189,  2219,  3997,     2,   583,    32,     1,   815,\n",
            "            1,     7, 11294,    18,   154,   324,  5672,     2,     1,\n",
            "          288,    11,  1600,   502,   127,  9059,   139,     2,   860,\n",
            "           37,    12,   597,     5,     2,   173,  1087,    40,    53,\n",
            "            2,    95,   419,     7,   121,  3352,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0]])>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMMruCKT0WsX"
      },
      "source": [
        "# 3 Convolutional Neural Network (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX9vv5TmjOoJ"
      },
      "source": [
        "# 2 Data Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJFcgcQj0JaF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8Qfn7nB0JVS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzCUtQqF0JIj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6pWc6HXkcvA"
      },
      "source": [
        "# 3 Convolutional Neural Network (CNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Oa_WfbyxF2Y"
      },
      "source": [
        "epochs = 5\n",
        "batch_size = 64\n",
        "maxlen = 500 # max number of words in the review\n",
        "max_features = 5000 # max number of words in the corpus\n",
        "embedding_dims = 128   # 50 # emddeding for each word\n",
        "#filters = 250\n",
        "#kernel_size = 3 #size of the 1D conv. layer\n",
        "hidden_dims = 250 # number of dimensions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WW9Cp32i3FYV"
      },
      "source": [
        "### Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elCwXkw-kdVa"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# we start off with an efficient embedding layer which maps\n",
        "# our vocab indices into embedding_dims dimensions\n",
        "model.add(Embedding(max_features,\n",
        "                     embedding_dims,\n",
        "                     input_length=maxlen))\n",
        "\n",
        "# Convolution layer 1\n",
        "model.add(Conv1D(filters,\n",
        "                 kernel_size,\n",
        "                 padding='valid',\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "\n",
        "# Max pooling\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "##### OTHER CONVOLUTION LAYERS #####\n",
        "\n",
        "# Flatten before connecting back \n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(hidden_dims))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Project onto a single unit, dense output layer and apply sigmoid activation function\n",
        "# to make 0 or 1 predictions for the two classes (positive or negative).\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0ZJpbncxv2F"
      },
      "source": [
        "# Use binary_crossentropy loss function as it is a binary classification problem \n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnWGkwij3IrO"
      },
      "source": [
        "### Predict test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnJnZDLJkdtj"
      },
      "source": [
        "history_cnn = model.fit(x_train, y_train,\n",
        "                      epochs=epochs,\n",
        "                      batch_size=batch_size,\n",
        "                      validation_split=0.1,\n",
        "                      callbacks=[EarlyStopping(monitor='val_loss',patience=3, min_delta=0.0001)])\n",
        "\n",
        "# history_cnn = model.fit(x_train, y_train,\n",
        "#           batch_size=batch_size,\n",
        "#           epochs=epochs,\n",
        "#           validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5aN803x3NMC"
      },
      "source": [
        "### Evaluate predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwuGTzOe2kuN",
        "outputId": "b21738c2-847a-456d-dcfb-486c75324dc1"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 400, 50)           250000    \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 398, 250)          37750     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 250)               62750     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 251       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 350,751\n",
            "Trainable params: 350,751\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45Q6BCam2Wi2",
        "outputId": "7b3f3563-7aba-4ea0-f1a9-b78332f43665"
      },
      "source": [
        "accuracy_cnn = model.evaluate(x_test,y_test,verbose=0)\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accuracy_cnn[0],accuracy_cnn[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set\n",
            "  Loss: 0.516\n",
            "  Accuracy: 0.891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hz2VSiGUnSlK",
        "outputId": "ff49449b-df6c-4732-bd01-0cbbe689de62"
      },
      "source": [
        "history_cnn.history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.999822199344635, 0.9999555349349976, 1.0, 1.0],\n",
              " 'loss': [0.003524243598803878,\n",
              "  0.001184531836770475,\n",
              "  0.00044091217569075525,\n",
              "  0.00026874570176005363],\n",
              " 'val_accuracy': [0.8980000019073486,\n",
              "  0.8980000019073486,\n",
              "  0.8971999883651733,\n",
              "  0.897599995136261],\n",
              " 'val_loss': [0.443440318107605,\n",
              "  0.4756409525871277,\n",
              "  0.49980345368385315,\n",
              "  0.5171829462051392]}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "YD6GW7KG2mHH",
        "outputId": "3e7ff3ec-d7d5-4a88-c2f2-ac6d96f9b1eb"
      },
      "source": [
        "plt.title('Loss')\n",
        "plt.plot(history_cnn.history['loss'], label='train')\n",
        "plt.plot(history_cnn.history['val_loss'], label='validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0iXLoWpkd6-"
      },
      "source": [
        "# 4 Long Short-Term Memory (LSTM) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4SYk2czkfk6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwohrjVUkf-I"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPPlmifnkgAZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oO-uFahvkgG8"
      },
      "source": [
        "# 5 Model Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKQ0ebz2kiIg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}